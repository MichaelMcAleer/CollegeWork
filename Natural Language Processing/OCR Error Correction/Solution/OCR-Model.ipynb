{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OCR-ErrorCorrection.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"UcQq0ZlVDo1V","colab_type":"code","outputId":"063b0120-ce83-45df-b063-1f9814c417e7","executionInfo":{"status":"ok","timestamp":1570955281769,"user_tz":-60,"elapsed":1033,"user":{"displayName":"Michael McAleer","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBA484SnEl51AELTFepW1wp9_GgYnxoLyFNlRtVUg=s64","userId":"03089754270101753013"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Import Google Drive and mount\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","root_path = '/content/drive/My Drive/Colab Notebooks/NLP/Assignment1'\n","\n","ExpDir = '{root}/OCR-System/'.format(root=root_path)\n","print('Experiment Dir is:' + ExpDir)\n","modelDir = '{ocr}/model/'.format(ocr=ExpDir)\n","print('Model is in:' + modelDir)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Experiment Dir is:/content/drive/My Drive/Colab Notebooks/NLP/Assignment1/OCR-System/\n","Model is in:/content/drive/My Drive/Colab Notebooks/NLP/Assignment1/OCR-System//model/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Se1nky49Fikg","colab_type":"code","colab":{}},"source":["import random\n","import sys\n","import numpy as np\n","import cv2\n","import editdistance\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35aOVI6HMfT5","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"jNqmyHsNFLOT","colab_type":"code","colab":{}},"source":["class FilePaths:\n","    \"\"\"filenames and paths to data\"\"\"\n","    fnCharList = modelDir + 'charList.txt'\n","    fnAccuracy = modelDir + 'accuracy.txt'\n","    fnInfer = ExpDir + 'test.png'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhtQMP7OFMxh","colab_type":"code","colab":{}},"source":["class Batch:\n","    \"\"\"batch containing images and ground truth texts\"\"\"\n","\n","    def __init__(self, gtTexts, imgs):\n","        self.imgs = np.stack(imgs, axis=0)\n","        self.gtTexts = gtTexts\n","\n","\n","class DecoderType:\n","    BestPath = 0\n","    BeamSearch = 1\n","    WordBeamSearch = 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2_rEArqFOTZ","colab_type":"code","colab":{}},"source":["def preprocess(img, imgSize, dataAugmentation=False):\n","    \"\"\"put img into target img of size imgSize, transpose for TF and normalize\n","    gray-values\"\"\"\n","    # there are damaged files in IAM dataset - just use black image instead\n","    if img is None:\n","        img = np.zeros([imgSize[1], imgSize[0]])\n","\n","    # increase dataset size by applying random stretches to the images\n","    if dataAugmentation:\n","        stretch = (random.random() - 0.5)  # -0.5 .. +0.5\n","        # random width, but at least 1\n","        wStretched = max(int(img.shape[1] * (1 + stretch)), 1)\n","        # stretch horizontally by factor 0.5 .. 1.5\n","        img = cv2.resize(img, (wStretched, img.shape[0]))\n","\n","    # create target image and copy sample image into it\n","    (wt, ht) = imgSize\n","    (h, w) = img.shape\n","    fx = w / wt\n","    fy = h / ht\n","    f = max(fx, fy)\n","    # scale according to f (result at least 1 and at most wt or ht)\n","    newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1))\n","    img = cv2.resize(img, newSize)\n","    target = np.ones([ht, wt]) * 255\n","    target[0:newSize[1], 0:newSize[0]] = img\n","\n","    # transpose for TF\n","    img = cv2.transpose(target)\n","\n","    # normalize\n","    (m, s) = cv2.meanStdDev(img)\n","    m = m[0][0]\n","    s = s[0][0]\n","    img = img - m\n","    img = img / s if s > 0 else img\n","    return img\n","\n","\n","def train(model, loader):\n","    \"train NN\"\n","    # number of training epochs since start\n","    epoch = 0\n","    # best valdiation character error rate\n","    bestCharErrorRate = float('inf')\n","    # number of epochs no improvement of character error rate occured\n","    noImprovementSince = 0\n","    # stop training after this number of epochs without improvement\n","    earlyStopping = 5\n","    while True:\n","        epoch += 1\n","        print('Epoch:', epoch)\n","\n","        # train\n","        print('Train NN')\n","        loader.trainSet()\n","        while loader.hasNext():\n","            iterInfo = loader.getIteratorInfo()\n","            batch = loader.getNext()\n","            loss = model.trainBatch(batch)\n","            print('Batch:', iterInfo[0], '/', iterInfo[1], 'Loss:', loss)\n","\n","        # validate\n","        charErrorRate = validate(model, loader)\n","\n","        # if best validation accuracy so far, save model parameters\n","        if charErrorRate < bestCharErrorRate:\n","            print('Character error rate improved, save model')\n","            bestCharErrorRate = charErrorRate\n","            noImprovementSince = 0\n","            model.save()\n","            open(FilePaths.fnAccuracy, 'w').write(\n","                'Validation character error rate of saved model: %f%%' % (\n","                        charErrorRate * 100.0))\n","        else:\n","            print('Character error rate not improved')\n","            noImprovementSince += 1\n","\n","        # stop training if no more improvement in the last x epochs\n","        if noImprovementSince >= earlyStopping:\n","            print('No more improvement since %d epochs. Training '\n","                  'stopped.' % earlyStopping)\n","            break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0FwPSvdFWQf","colab_type":"code","colab":{}},"source":["def validate(model, loader):\n","    \"validate NN\"\n","    print('Validate NN')\n","    loader.validationSet()\n","    numCharErr = 0\n","    numCharTotal = 0\n","    numWordOK = 0\n","    numWordTotal = 0\n","    while loader.hasNext():\n","        iterInfo = loader.getIteratorInfo()\n","        print('Batch:', iterInfo[0], '/', iterInfo[1])\n","        batch = loader.getNext()\n","        recognized = model.inferBatch(batch)\n","\n","        print('Ground truth -> Recognized')\n","        for i in range(len(recognized)):\n","            numWordOK += 1 if batch.gtTexts[i] == recognized[i] else 0\n","            numWordTotal += 1\n","            dist = editdistance.eval(recognized[i], batch.gtTexts[i])\n","            numCharErr += dist\n","            numCharTotal += len(batch.gtTexts[i])\n","            print('[OK]' if dist == 0 else '[ERR:%d]' % dist,\n","                  '\"' + batch.gtTexts[i] + '\"', '->',\n","                  '\"' + recognized[i] + '\"')\n","\n","    # print validation result\n","    charErrorRate = numCharErr / numCharTotal\n","    wordAccuracy = numWordOK / numWordTotal\n","    print('Character error rate: %f%%. Word accuracy: %f%%.' % (\n","        charErrorRate * 100.0, wordAccuracy * 100.0))\n","    return charErrorRate"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r0X8uXPAFb70","colab_type":"code","colab":{}},"source":["class Model:\n","    \"minimalistic TF model for HTR\"\n","\n","    # model constants\n","    batchSize = 50\n","    imgSize = (128, 32)\n","    maxTextLen = 32\n","\n","    def __init__(self, charList, decoderType=DecoderType.BestPath,\n","                 mustRestore=False):\n","        \"init model: add CNN, RNN and CTC and initialize TF\"\n","        self.charList = charList\n","        self.decoderType = decoderType\n","        self.mustRestore = mustRestore\n","        self.snapID = 0\n","\n","        # CNN\n","        self.inputImgs = tf.placeholder(\n","            tf.float32, shape=(Model.batchSize,\n","                               Model.imgSize[0],\n","                               Model.imgSize[1]))\n","        cnnOut4d = self.setupCNN(self.inputImgs)\n","\n","        # RNN\n","        rnnOut3d = self.setupRNN(cnnOut4d)\n","\n","        # CTC\n","        (self.loss, self.decoder) = self.setupCTC(rnnOut3d)\n","\n","        # optimizer for NN parameters\n","        self.batchesTrained = 0\n","        self.learningRate = tf.placeholder(tf.float32, shape=[])\n","        self.optimizer = tf.train.RMSPropOptimizer(\n","            self.learningRate).minimize(self.loss)\n","\n","        # initialize TF\n","        (self.sess, self.saver) = self.setupTF()\n","\n","    def setupCNN(self, cnnIn3d):\n","        \"create CNN layers and return output of these layers\"\n","        cnnIn4d = tf.expand_dims(input=cnnIn3d, axis=3)\n","\n","        # list of parameters for the layers\n","        kernelVals = [5, 5, 3, 3, 3]\n","        featureVals = [1, 32, 64, 128, 128, 256]\n","        strideVals = poolVals = [(2, 2), (2, 2), (1, 2), (1, 2), (1, 2)]\n","        numLayers = len(strideVals)\n","\n","        # create layers\n","        pool = cnnIn4d  # input to first CNN layer\n","        for i in range(numLayers):\n","            kernel = tf.Variable(tf.truncated_normal(\n","                [kernelVals[i], kernelVals[i], featureVals[i],\n","                 featureVals[i + 1]], stddev=0.1))\n","            conv = tf.nn.conv2d(pool, kernel, padding='SAME',\n","                                strides=(1, 1, 1, 1))\n","            relu = tf.nn.relu(conv)\n","            pool = tf.nn.max_pool(relu,\n","                                  (1, poolVals[i][0], poolVals[i][1], 1),\n","                                  (1, strideVals[i][0], strideVals[i][1], 1),\n","                                  'VALID')\n","\n","        return pool\n","\n","    def setupRNN(self, rnnIn4d):\n","        \"create RNN layers and return output of these layers\"\n","        rnnIn3d = tf.squeeze(rnnIn4d, axis=[2])\n","\n","        # basic cells which is used to build RNN\n","        numHidden = 256\n","        # 2 layers\n","        cells = [\n","            tf.contrib.rnn.LSTMCell(\n","                num_units=numHidden, state_is_tuple=True) for _ in range(2)]\n","\n","        # stack basic cells\n","        stacked = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n","\n","        # bidirectional RNN\n","        # BxTxF -> BxTx2H\n","        ((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(\n","            cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d,\n","            dtype=rnnIn3d.dtype)\n","\n","        # BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n","        concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n","\n","        # project output to chars (including blank):\n","        # BxTx1x2H -> BxTx1xC -> BxTxC\n","        kernel = tf.Variable(\n","            tf.truncated_normal(\n","                [1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n","        return tf.squeeze(tf.nn.atrous_conv2d(\n","            value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n","\n","    def setupCTC(self, ctcIn3d):\n","        \"create CTC loss and decoder and return them\"\n","        # BxTxC -> TxBxC\n","        ctcIn3dTBC = tf.transpose(ctcIn3d, [1, 0, 2])\n","        # ground truth text as sparse tensor\n","        self.gtTexts = tf.SparseTensor(\n","            tf.placeholder(tf.int64, shape=[None, 2]),\n","            tf.placeholder(tf.int32, [None]),\n","            tf.placeholder(tf.int64, [2]))\n","        # calc loss for batch\n","        self.seqLen = tf.placeholder(tf.int32, [None])\n","        loss = tf.nn.ctc_loss(\n","            labels=self.gtTexts, inputs=ctcIn3dTBC,\n","            sequence_length=self.seqLen, ctc_merge_repeated=True)\n","        # decoder: either best path decoding or beam search decoding\n","        if self.decoderType == DecoderType.BestPath:\n","            decoder = tf.nn.ctc_greedy_decoder(inputs=ctcIn3dTBC,\n","                                               sequence_length=self.seqLen)\n","        elif self.decoderType == DecoderType.BeamSearch:\n","            decoder = tf.nn.ctc_beam_search_decoder(\n","                inputs=ctcIn3dTBC, sequence_length=self.seqLen, beam_width=50,\n","                merge_repeated=False)\n","        elif self.decoderType == DecoderType.WordBeamSearch:\n","            # import compiled word beam search operation\n","            # (see https://github.com/githubharald/CTCWordBeamSearch)\n","            word_beam_search_module = tf.load_op_library('TFWordBeamSearch.so')\n","\n","            # prepare information about language (dictionary, characters in\n","            # dataset, characters forming words)\n","            chars = str().join(self.charList)\n","            wordChars = open(\n","                modelDir + 'wordCharList.txt').read().splitlines()[0]\n","            corpus = open(modelDir + 'corpus.txt').read()\n","\n","            # decode using the \"Words\" mode of word beam search\n","            decoder = word_beam_search_module.word_beam_search(\n","                tf.nn.softmax(ctcIn3dTBC, dim=2), 50, 'Words', 0.0,\n","                corpus.encode('utf8'), chars.encode('utf8'),\n","                wordChars.encode('utf8'))\n","\n","        # return a CTC operation to compute the loss and a CTC operation to\n","        # decode the RNN output\n","        return (tf.reduce_mean(loss), decoder)\n","\n","    def setupTF(self):\n","        \"initialize TF\"\n","        print('Python: ' + sys.version)\n","        print('Tensorflow: ' + tf.__version__)\n","\n","        # TF session\n","        sess = tf.Session()\n","        # saver saves model to file\n","        saver = tf.train.Saver(max_to_keep=1)\n","        # is there a saved model?\n","        latestSnapshot = tf.train.latest_checkpoint(modelDir)\n","\n","        # if model must be restored (for inference), there must be a snapshot\n","        if self.mustRestore and not latestSnapshot:\n","            raise Exception('No saved model found in: ' + modelDir)\n","\n","        # load saved model if available\n","        if latestSnapshot:\n","            print('Init with stored values from ' + latestSnapshot)\n","            saver.restore(sess, latestSnapshot)\n","        else:\n","            print('Init with new values')\n","            sess.run(tf.global_variables_initializer())\n","\n","        return (sess, saver)\n","\n","    def toSparse(self, texts):\n","        \"put ground truth texts into sparse tensor for ctc_loss\"\n","        indices = []\n","        values = []\n","        shape = [len(texts), 0]  # last entry must be max(labelList[i])\n","\n","        # go over all texts\n","        for (batchElement, text) in enumerate(texts):\n","            # convert to string of label (i.e. class-ids)\n","            labelStr = [self.charList.index(c) for c in text]\n","            # sparse tensor must have size of max. label-string\n","            if len(labelStr) > shape[1]:\n","                shape[1] = len(labelStr)\n","            # put each label into sparse tensor\n","            for (i, label) in enumerate(labelStr):\n","                indices.append([batchElement, i])\n","                values.append(label)\n","\n","        return (indices, values, shape)\n","\n","    def decoderOutputToText(self, ctcOutput):\n","        \"extract texts from output of CTC decoder\"\n","\n","        # contains string of labels for each batch element\n","        encodedLabelStrs = [[] for i in range(Model.batchSize)]\n","\n","        # word beam search: label strings terminated by blank\n","        if self.decoderType == DecoderType.WordBeamSearch:\n","            blank = len(self.charList)\n","            for b in range(Model.batchSize):\n","                for label in ctcOutput[b]:\n","                    if label == blank:\n","                        break\n","                    encodedLabelStrs[b].append(label)\n","\n","        # TF decoders: label strings are contained in sparse tensor\n","        else:\n","            # ctc returns tuple, first element is SparseTensor\n","            decoded = ctcOutput[0][0]\n","\n","            # go over all indices and save mapping: batch -> values\n","            # idxDict = {b: [] for b in range(Model.batchSize)}\n","            for (idx, idx2d) in enumerate(decoded.indices):\n","                label = decoded.values[idx]\n","                # index according to [b,t]\n","                batchElement = idx2d[0]\n","                encodedLabelStrs[batchElement].append(label)\n","\n","        # map labels to chars for all batch elements\n","        return [\n","            str().join([self.charList[c] for c in labelStr]) for\n","            labelStr in encodedLabelStrs]\n","\n","    def trainBatch(self, batch):\n","        \"feed a batch into the NN to train it\"\n","        sparse = self.toSparse(batch.gtTexts)\n","        # decay learning rate\n","        rate = 0.01 if self.batchesTrained < 10 else (\n","            0.001 if self.batchesTrained < 10000 else 0.0001)\n","        (_, lossVal) = self.sess.run(\n","            [self.optimizer, self.loss],\n","            {self.inputImgs: batch.imgs,\n","             self.gtTexts: sparse,\n","             self.seqLen: [Model.maxTextLen] * Model.batchSize,\n","             self.learningRate: rate})\n","        self.batchesTrained += 1\n","        return lossVal\n","\n","    def inferBatch(self, batch):\n","        \"feed a batch into the NN to recngnize the texts\"\n","        decoded = self.sess.run(\n","            self.decoder,\n","            {self.inputImgs: batch.imgs,\n","             self.seqLen: [Model.maxTextLen] * Model.batchSize})\n","        return self.decoderOutputToText(decoded)\n","\n","    def save(self):\n","        \"save model to file\"\n","        self.snapID += 1\n","        self.saver.save(self.sess, 'model/snapshot', global_step=self.snapID)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQR5CFTDFdbX","colab_type":"code","colab":{}},"source":["def infer(model, fnImg):\n","    \"recognize text in image provided by file path\"\n","    img = preprocess(cv2.imread(fnImg, cv2.IMREAD_GRAYSCALE), Model.imgSize)\n","    # fill all batch elements with same input image\n","    batch = Batch(None, [img] * Model.batchSize)\n","    # recognize text\n","    recognized = model.inferBatch(batch)\n","    # all batch elements hold same result\n","    print('Recognized:', '\"' + recognized[0] + '\"')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VZGXbMd7Fe65","colab_type":"code","colab":{}},"source":["def main():\n","    \"main function\"\n","\n","    decoderType = DecoderType.BestPath\n","\n","    print(open(FilePaths.fnAccuracy).read())\n","    model = Model(open(FilePaths.fnCharList).read(),\n","                  decoderType, mustRestore=True)\n","    infer(model, FilePaths.fnInfer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAZKZMqZFgVT","colab_type":"code","outputId":"cf97991b-9076-4871-a9e8-1bd0506d08b2","executionInfo":{"status":"ok","timestamp":1570955294096,"user_tz":-60,"elapsed":13284,"user":{"displayName":"Michael McAleer","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBA484SnEl51AELTFepW1wp9_GgYnxoLyFNlRtVUg=s64","userId":"03089754270101753013"}},"colab":{"base_uri":"https://localhost:8080/","height":671}},"source":["if __name__ == '__main__':\n","    main()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Validation character error rate of saved model: 13.956289%\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-9-7fab1311c33f>:74: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-9-7fab1311c33f>:77: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-9-7fab1311c33f>:83: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","Python: 3.6.8 (default, Jan 14 2019, 11:02:34) \n","[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n","Tensorflow: 1.15.0-rc3\n","Init with stored values from /content/drive/My Drive/Colab Notebooks/NLP/Assignment1/OCR-System//model/snapshot-32\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Colab Notebooks/NLP/Assignment1/OCR-System//model/snapshot-32\n","Recognized: \"little\"\n"],"name":"stdout"}]}]}